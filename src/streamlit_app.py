# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Crossâ€‘Check Framework  â€¢  StreamlitÂ Simulation App
#  v2025â€‘07â€‘30  â€“  UIâ€‘centric MC & Sobol  (all params Â±Î±â€¯% around UI)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  (c) 2025 digitalian  â€“  MITÂ License
# ----------------------------------------------------------------
#  Changelog (since 2025â€‘07â€‘29)
#   â€¢ CHANGE: Monteâ€¯Carlo â€“ every parameter now sampled around the UI value
#   â€¢ CHANGE: Sobol â€“ bounds dynamically follow current UI baseline (Â±Î±â€¯%)
#   â€¢ ADD   : Bold headings ğŸ”¶ for "highâ€‘uncertainty" params (PP,Â â„“, Tâ‚â€“Tâ‚ƒ)
#   â€¢ ADD   : Toolâ€‘tips / expander text updated to reflect new sampling logic
# ----------------------------------------------------------------

from __future__ import annotations

import streamlit as st
import numpy as np, math
import sympy as sp
import pandas as pd
import plotly.express as px
from typing import Tuple, Dict, List

st.set_page_config(
    page_title="Cross-Check Simulator",
    layout="wide"
)

# â”€â”€ New: SALib for Sobol â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from SALib.sample.sobol import sample as sobol_sample   # SALib â‰¥1.5
except ImportError:
    from SALib.sample import saltelli as sobol_sample       # SALib â‰¤1.4
from SALib.analyze import sobol

# â”€â”€ New: PCG64DXSM generator (fast & parallelâ€‘safe) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from numpy.random import PCG64DXSM, Generator

# --- Localisation dictionaries (English & Japanese) -------------
# *Monteâ€¯Carlo / Sobol èª¬æ˜æ–‡ã‚’ UI åŸºæº– Â±Î±% ä»•æ§˜ã«æ›¸ãæ›ãˆ*
# â–‘â–‘â–‘  Language packs with super-detailed, publication-ready wording  â–‘â–‘â–‘
#  *Key structure is 100 % backward-compatible with the original code.*

TXT_EN = {
    "panel": {
        "input": "INPUT PANEL",
        "output": "KEY OUTPUT METRICS",
    },
    "metrics": {
        "a_total": "a_total",
        "succ": "Success Rate S",
        "C": "Labor Cost C",
        "Closs": "C_total (incl. loss)",
        "loss_unit": "Loss unit â„“",
        "E_base": "Efficiency E (baseline)",
        "E_total": "E_total",
    },
    "charts": {
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        "quality_schedule": {
            "title": "Quality Ã— Schedule 2 Ã— 2 Matrix",
            "expander_title": "ğŸ“˜ About the Quality Ã— Schedule Chart",
            "expander_content": (
                "This 2 Ã— 2 bar chart conveys the combined impact of the **quality policy** "
                "(e.g., â€˜Standardâ€™ vs â€˜Lowâ€™) and the **schedule policy** "
                "(â€˜On-timeâ€™ vs â€˜Lateâ€™) on the total cost-per-success **E_total**.  \n\n"
                "- **Bar height = E_total**  (the lower, the better).  \n"
                "- **Bar label = success probability S**  (shown as a percentage).  \n\n"
                "Reading tip  â†’  Compare the four cells horizontally and vertically to "
                "discern whether quality or schedule exerts a stronger economic leverage "
                "under the current parameter baseline."
            ),
        },
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        "tornado": {
            "title": "Local Tornado Sensitivity (Â±20 %)",
            "expander_title": "ğŸ“˜ Interpreting the Tornado Diagram",
            "expander_content": (
                "The tornado diagram quantifies the **local (one-at-a-time) sensitivity** of "
                "E_total to each input parameter by perturbing that parameter Â±20 % around "
                "its current UI value *while holding all others fixed*.  \n\n"
                "- **Bar length |Î”E/E|**  = relative change in E_total.  \n"
                "- **Ordering**  = bars are sorted from the most to the least influential, "
                "making the plot visually resemble a tornado.  \n\n"
                "Use this view to prioritise which parameter warrants the most immediate "
                "attention when performing local optimisation or design-of-experiments."
            ),
            "xaxis": "|Î”E/E|",
        },
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        "sobol": {
            "title": "Global Sensitivity (Sobol Sâ‚)",
            "expander_title": "ğŸ“˜ Sobol Global Sensitivity Analysis",
            "expander_content": (
                "We perform a variance-based global sensitivity analysis employing the "
                "Saltelli extension of Sobolâ€™ sampling.  \n\n"
                "- **Sampling bounds**  = each parameter is allowed to vary within Â±Î± % of "
                "its UI baseline (Î± depends on the parameter class; see code comments).  \n"
                "- **Displayed metric**  = first-order Sobol index **Sâ‚**, which represents "
                "the fraction of total output variance attributable to that parameter alone, "
                "excluding interaction effects.  \n\n"
                "A larger Sâ‚ indicates a stronger contribution to the uncertainty of "
                "E_total across the multidimensional parameter space."
            ),
            "xaxis": "Sobol Sâ‚",
        },
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        "relative_sensitivity": {
            "title": "Relative Elasticity",
            "xaxis": "Relative Sensitivity  (âˆ‚E/âˆ‚x Â· x / E)",
            "expander_title": "ğŸ“˜ Relative vs Standardised Sensitivity",
            "expander_content": (
                "**Relative (elasticity)** expresses how many percent E_total changes in "
                "response to a 1 % proportional change in a given parameter (i.e., a "
                "dimension-free slope).  \n\n"
                "In contrast, **Standardised sensitivity** scales the partial derivative "
                "by the parameterâ€™s own standard deviation, illuminating which sources of "
                "uncertainty dominate the overall variability.  \n\n"
                "In practice, high elasticity indicates a *lever* for managerial control, "
                "whereas high standardised sensitivity signals a *risk* that should be "
                "mitigated (e.g., via additional data collection or process stabilisation)."
            ),
        },
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        "standardized_sensitivity": {
            "title": "Standardised Sensitivity",
            "xaxis": "Standardised Sensitivity  (Î”E / Ïƒ_E)",
            "expander_title": "ğŸ“˜ Standardised Sensitivity (Ïƒ-normalised)",
            "expander_content": (
                "Computed as (âˆ‚E/âˆ‚x) Â· Ïƒâ‚“ / Ïƒ_E, this metric places all parameters on a "
                "common variance-normalised footing. A value of 1 implies that a "
                "one-standard-deviation shock in the parameter shifts E_total by one "
                "standard deviation, ceteris paribus."
            ),
        },
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        "monte_carlo": {
            "title": "Monte-Carlo Summary",
            "expander_title": "ğŸ“˜ Monte-Carlo Input Distributions",
            "expander_content": (
                "Each uncertain parameter is stochastically sampled around the *current UI "
                "value* to emulate real-world process variability.  \n\n"
                "â€¢ **aâ‚, aâ‚‚**   Normal (Î¼ = UI, Ïƒ = 3 % Î¼)  \n"
                "â€¢ **aâ‚ƒ**       Triangular (lower = 0.9 Î¼, mode = Î¼, upper = 1.1 Î¼)  \n"
                "â€¢ **bâ‚€**       Uniform [max(0, Î¼âˆ’0.10), min(1, Î¼+0.10)]  \n"
                "â€¢ **CR, PP**   Triangular [0.8 Î¼, Î¼, 1.2 Î¼]  \n"
                "â€¢ **â„“**        Triangular [0.8 Î¼, Î¼, 1.2 Î¼]  \n"
                "â€¢ **Tâ‚â€“Tâ‚ƒ**    Normal (Î¼ = UI, Ïƒ = 10 % Î¼)  \n\n"
                "_If the UI value of CR, PP, or â„“ is **zero**, the parameter is kept at "
                "zero (i.e., no stochastic variation is introduced)._  \n\n"
                "The resulting histogram overlays the mean (solid line), median (solid line), "
                "and 5â€“95 % credible interval (dotted lines) to provide an at-a-glance view "
                "of central tendency and dispersion."
            ),
            "variable": "MC variable",
            "mean": "Mean",
            "median": "Median",
            "ci": "5â€“95 % CI",
            "caption": {
                "en": "Histogram with mean (solid), median (solid), 5â€“95 % CI (dotted)",
                "ja": "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼šå¹³å‡/ä¸­å¤®å€¤ï¼å®Ÿç·šã€ä¿¡é ¼åŒºé–“ï¼ç‚¹ç·š"
            },
            "card_unit": "[E_total]",
        },
    },
}
TXT_JA = {
    "panel": {
        "input": "å…¥åŠ›ãƒ‘ãƒãƒ«",
        "output": "ä¸»è¦å‡ºåŠ›æŒ‡æ¨™",
    },
    "metrics": {
        "a_total": "a_total",
        "succ": "æˆåŠŸç‡ S",
        "C": "Cï¼ˆä½œæ¥­å·¥æ•°ï¼‰",
        "Closs": "C_totalï¼ˆæå¤±è¾¼ï¼‰",
        "loss_unit": "æå¤±å˜ä¾¡ â„“",
        "E_base": "åŠ¹ç‡ Eï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰",
        "E_total": "E_total",
    },
    "charts": {
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        "quality_schedule": {
            "title": "å“è³ª Ã— ç´æœŸ 2 Ã— 2 ãƒãƒˆãƒªã‚¯ã‚¹",
            "expander_title": "ğŸ“˜ ãƒãƒ£ãƒ¼ãƒˆã®èª­ã¿æ–¹",
            "expander_content": (
                "æ¨ªè»¸ã«å“è³ªï¼ˆæ¨™æº–ï¼ä½ï¼‰ã€ç¸¦è»¸ã«ç´æœŸï¼ˆã‚ªãƒ³ã‚¿ã‚¤ãƒ ï¼é…å»¶ï¼‰ã® "
                "2 Ã— 2 çµ„ã¿åˆã‚ã›ã‚’é…ç½®ã—ã€å„ãƒãƒ¼ã®é«˜ã•ã§ **E_total** "
                "ï¼ˆæˆåŠŸ 1 ä»¶ã‚ãŸã‚Šç·ã‚³ã‚¹ãƒˆï¼‰ã‚’ç¤ºã—ã¾ã™ã€‚ãƒãƒ¼ä¸Šã®ãƒ©ãƒ™ãƒ«ã¯ "
                "å¯¾å¿œã™ã‚‹æˆåŠŸç‡ **S** ã‚’ç™¾åˆ†ç‡ã§è¡¨ç¤ºã—ã¾ã™ã€‚  \n\n"
                "ğŸ‘‰ 4 é€šã‚Šã®ã‚·ãƒŠãƒªã‚ªã‚’ä¸€ç›®ã§æ¯”è¼ƒã—ã€å“è³ªæ–½ç­–ã¨ç´æœŸæ–½ç­–ã® "
                "ã©ã¡ã‚‰ãŒçµŒæ¸ˆçš„ã«å„ªä½ã‹ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚"
            ),
        },
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        "tornado": {
            "title": "ãƒ­ãƒ¼ã‚«ãƒ« ãƒˆãƒ«ãƒãƒ¼ãƒ‰æ„Ÿåº¦ (Â±20 %)",
            "expander_title": "ğŸ“˜ ãƒˆãƒ«ãƒãƒ¼ãƒ‰å›³ã¨ã¯",
            "expander_content": (
                "å„å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ **UI å€¤ã‹ã‚‰ Â±20 %** ã ã‘å˜ç‹¬ã§å¤‰å‹•ã•ã›ã€"
                "ãã®ã¨ãã®ã‚³ã‚¹ãƒˆåŠ¹ç‡ **E_total** ã®ç›¸å¯¾å¤‰åŒ– |Î”E/E| ã‚’ãƒãƒ¼ã®é•·ã• "
                "ã¨ã—ã¦æç”»ã—ã¾ã™ã€‚  \n\n"
                "ãƒãƒ¼ãŒé•·ã„ï¼ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒ **å±€æ‰€çš„** ã«æœ€ã‚‚å¼·ã„å½±éŸ¿ã‚’æŒã¤ "
                "ã“ã¨ã‚’æ„å‘³ã—ã€æ”¹å–„ãƒ»èª¿æ•´ã®å„ªå…ˆåº¦ã‚’ç¤ºå”†ã—ã¾ã™ã€‚"
            ),
            "xaxis": "|Î”E/E|",
        },
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        "sobol": {
            "title": "ã‚°ãƒ­ãƒ¼ãƒãƒ«æ„Ÿåº¦ (Sobol Sâ‚)",
            "expander_title": "ğŸ“˜ Sobol æ„Ÿåº¦è§£æã®æ¦‚è¦",
            "expander_content": (
                "Saltelli æ‹¡å¼µã‚’ç”¨ã„ãŸ Sobol æ³•ã§ã€å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ UI åŸºæº–å€¤ Â±Î± % "
                "ã®ç¯„å›²ã§åŒæ™‚ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€**E_total** ã®åˆ†æ•£ã«å¯¾ã™ã‚‹ä¸€æ¬¡å¯„ä¸ "
                "ï¼ˆSobol æŒ‡æ•° **Sâ‚**ï¼‰ã‚’ç®—å‡ºã—ã¾ã™ã€‚  \n\n"
                "Sâ‚ ãŒå¤§ãã„ã»ã©ã€ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å˜ç‹¬ã§çµæœã®ä¸ç¢ºå®Ÿæ€§ã‚’å·¦å³ã—ã¦ã„ã‚‹ "
                "åº¦åˆã„ãŒé«˜ã„ã¨è§£é‡ˆã§ãã¾ã™ã€‚"
            ),
            "xaxis": "Sobol Sâ‚",
        },
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        "relative_sensitivity": {
            "title": "ç›¸å¯¾å¼¾æ€§å€¤",
            "xaxis": "ç›¸å¯¾æ„Ÿåº¦ (âˆ‚E/âˆ‚xÂ·x/E)",
            "expander_title": "ğŸ“˜ æŒ‡æ¨™ã®æ„å‘³ã¨æ´»ç”¨",
            "expander_content": (
                "ç›¸å¯¾å¼¾æ€§å€¤ï¼ˆElasticityï¼‰ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ 1 % å¤‰åŒ–ã•ã›ãŸéš›ã« "
                "**E_total** ãŒä½•ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå¤‰å‹•ã™ã‚‹ã‹ã‚’ç¤ºã™æ¬¡å…ƒãƒ¬ã‚¹é‡ã§ã™ã€‚  \n\n"
                "å€¤ãŒå¤§ãã„ã»ã© â€œã¦ã“ã®åŸç†â€ ãŒåŠ¹ãã‚„ã™ãã€ã‚³ã‚¹ãƒˆåŠ¹ç‡æ”¹å–„ã® "
                "ãƒ¬ãƒãƒ¼ã¨ã—ã¦æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¾ã™ã€‚"
            ),
        },
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        "standardized_sensitivity": {
            "title": "æ¨™æº–åŒ–æ„Ÿåº¦",
            "xaxis": "æ¨™æº–åŒ–æ„Ÿåº¦ (Î”E/Ïƒ_E)",
            "expander_title": "ğŸ“˜ æ¨™æº–åŒ–æ„Ÿåº¦ã¨ã¯",
            "expander_content": (
                "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¨™æº–åå·® Ïƒâ‚“ ã§æ­£è¦åŒ–ã—ãŸæ„Ÿåº¦ "
                "(âˆ‚E/âˆ‚x)Â·Ïƒâ‚“/Ïƒ_E ã‚’ç¤ºã—ã¾ã™ã€‚  \n\n"
                "å¤§ãã„å€¤ã¯ã€ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¸ç¢ºå®Ÿæ€§ãŒ **E_total** ã®å¤‰å‹•ã« "
                "å¤§ããå¯„ä¸ã—ã¦ã„ã‚‹ã€ã“ã¨ã‚’ç¤ºã—ã€ãƒªã‚¹ã‚¯ç®¡ç†ã‚„ãƒ‡ãƒ¼ã‚¿åé›†ã® "
                "å„ªå…ˆåº¦ä»˜ã‘ã«å½¹ç«‹ã¡ã¾ã™ã€‚"
            ),
        },
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        "monte_carlo": {
            "title": "ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­è¦ç´„",
            "expander_title": "ğŸ“˜ å…¥åŠ›åˆ†å¸ƒã®è¨­å®š (UI åŸºæº–)",
            "expander_content": (
                "å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ **ç¾åœ¨ã® UI å€¤** ã‚’ä¸­å¿ƒã«ä»¥ä¸‹ã®åˆ†å¸ƒã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° "
                "ã•ã‚Œã¾ã™ï¼š  \n\n"
                "â€¢ **aâ‚, aâ‚‚**  æ­£è¦åˆ†å¸ƒ (Î¼ = UI, Ïƒ = 3 % Î¼)  \n"
                "â€¢ **aâ‚ƒ**      ä¸‰è§’åˆ†å¸ƒ (ä¸‹é™ = 0.9 Î¼, ãƒ¢ãƒ¼ãƒ‰ = Î¼, ä¸Šé™ = 1.1 Î¼)  \n"
                "â€¢ **bâ‚€**      ä¸€æ§˜åˆ†å¸ƒ [max(0, Î¼âˆ’0.10), min(1, Î¼+0.10)]  \n"
                "â€¢ **CR, PP**  ä¸‰è§’åˆ†å¸ƒ [0.8 Î¼, Î¼, 1.2 Î¼]  \n"
                "â€¢ **â„“**       ä¸‰è§’åˆ†å¸ƒ [0.8 Î¼, Î¼, 1.2 Î¼]  \n"
                "â€¢ **Tâ‚â€“Tâ‚ƒ**   æ­£è¦åˆ†å¸ƒ (Î¼ = UI, Ïƒ = 10 % Î¼)  \n\n"
                "â€» **CRãƒ»PPãƒ»â„“ ã® UI å€¤ãŒ 0** ã®å ´åˆã€ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ 0 ã«å›ºå®šã•ã‚Œ "
                "å¤‰å‹•ã‚’ä¸ãˆã¾ã›ã‚“ã€‚  \n\n"
                "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã«ã¯å¹³å‡ï¼ˆå®Ÿç·šï¼‰ã€ä¸­å¤®å€¤ï¼ˆå®Ÿç·šï¼‰ã€ä¿¡é ¼åŒºé–“ 5â€“95 % "
                "ï¼ˆç‚¹ç·šï¼‰ãŒé‡ã­æãã•ã‚Œã€ä¸­å¿ƒå‚¾å‘ã¨ã°ã‚‰ã¤ããŒä¸€ç›®ã§æŠŠæ¡ã§ãã¾ã™ã€‚"
            ),
            "variable": "MCå¯¾è±¡å¤‰æ•°",
            "mean": "å¹³å‡",
            "median": "ä¸­å¤®å€¤",
            "ci": "5â€“95 % CI",
            "caption": {
                "en": "Histogram with mean (solid), median (solid), 5â€“95 % CI (dotted)",
                "ja": "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼šå¹³å‡/ä¸­å¤®å€¤ï¼å®Ÿç·šã€ä¿¡é ¼åŒºé–“ï¼ç‚¹ç·š"
            },
            "card_unit": "[E_total]",
        },
    },
}
# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ ã­ã“èª UI ãƒ‘ãƒƒã‚¯ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
# ï¼Šè‹±èª(JA)ã¨åŒã˜ã‚­ãƒ¼æ§‹é€ ãªã®ã§ drop-in ç½®æ›ã§ãã‚‹ã«ã‚ƒï¼Š

TXT_CAT = {
    "panel": {
        "input": "ã«ã‚…ã†ã‚Šã‚‡ã ã±ã­ã‚‹ ã«ã‚ƒ",
        "output": "ãŸã„ã›ã¤ ã‘ã£ã‹ ã«ã‚ƒ",
    },

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "metrics": {
        "a_total": "a_total ã«ã‚ƒ",
        "succ": "ã›ã„ã“ã†ã‚Šã¤ S ã«ã‚ƒ",
        "C": "ãŠã—ã”ã¨ã‚³ã‚¹ãƒˆ C ã«ã‚ƒ",
        "Closs": "C_total (ãã‚“ã—ã¤ã“ã¿) ã«ã‚ƒ",
        "loss_unit": "ãã‚“ã—ã¤ãŸã‚“ã‹ â„“ ã«ã‚ƒ",
        "E_base": "ã“ã†ã‚Šã¤ E (ã¹ãƒ¼ã™) ã«ã‚ƒ",
        "E_total": "E_total ã«ã‚ƒ",
    },

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "charts": {
        # 1) å“è³ªÃ—ç´æœŸ
        "quality_schedule": {
            "title": "ã²ã‚“ã—ã¤ Ã— ã®ã†ã 2Ã—2 ã«ã‚ƒ",
            "expander_title": "ğŸ“˜ ã“ã‚Œãªã‚ã«ï¼Ÿ ã«ã‚ƒ",
            "expander_content": (
                "ï¼”ã¤ã®ãƒãƒ¼ã§ **E_total** ã®ãŸã‹ã•ã‚’ãã‚‰ã¹ã‚‹ã«ã‚ƒã€‚"
                "ãƒãƒ¼ã®ã†ãˆã®æ•°å­—ã¯ **S** (ã›ã„ã“ã†ï¼…) ã«ã‚ƒã€‚\n\n"
                "ã­ã“ãƒã‚¤ãƒ³ãƒˆï¼šã‚ˆã“åˆ—ãƒ»ãŸã¦åˆ—ã§ã€ã©ã£ã¡ãŒãƒˆã‚¯ï¼Ÿã€ã‚’è¦‹ã¤ã‘ã‚‹ã«ã‚ƒã€œğŸ¾"
            ),
        },

        # 2) ãƒˆãƒ«ãƒãƒ¼ãƒ‰
        "tornado": {
            "title": "ã¨ã‚‹ã­ãƒ¼ã© ãŒã‚“ã© (Â±20%) ã«ã‚ƒ",
            "expander_title": "ğŸ“˜ ãã‚‹ãã‚‹æ£’ã®ã²ã¿ã¤ ã«ã‚ƒ",
            "expander_content": (
                "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ï¼‘ã“ãšã¤ Â±20% ã†ã”ã‹ã—ã¦ "
                "**|Î”E/E|** (E_total ã®ã¸ã‚“ã‹) ã‚’æ£’ã®ãªãŒã•ã§è¦‹ã›ã‚‹ã«ã‚ƒã€‚\n\n"
                "ãªãŒã€œã„æ£’ â†’ ã€ã“ã“ ãªãŠã™ã¨ ã„ã¡ã°ã‚“ ããï¼ã€ ã«ã‚ƒğŸ±"
            ),
            "xaxis": "|Î”E/E| ã«ã‚ƒ",
        },

        # 3) ã‚½ãƒ¼ãƒœãƒ«
        "sobol": {
            "title": "ããƒ¼ã¼ã‚‹ Sâ‚ ã«ã‚ƒ",
            "expander_title": "ğŸ“˜ ããƒ¼ã¼ã‚‹ï¼Ÿ ãŠã„ã—ã„ï¼Ÿ ã«ã‚ƒ",
            "expander_content": (
                "ãœã‚“ã¶ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ ã„ã£ã›ã„ã« ãƒ¦ã‚µãƒ¦ã‚µã—ã¦ "
                "ã¶ã‚Œã®ã‚ã‚Šã‚ã„ **Sâ‚** ã‚’ã¯ã‹ã‚‹ã«ã‚ƒã€‚\n\n"
                "Sâ‚ ãŒ 1 ã«ã¡ã‹ã„ â†’ ãã®å­ã ã‘ã§ å¤§ã‚ã°ã‚Œ ã«ã‚ƒï¼"
            ),
            "xaxis": "Sâ‚ ã«ã‚ƒ",
        },

        # 4) ç›¸å¯¾å¼¾æ€§åº¦
        "relative_sensitivity": {
            "title": "ãã†ãŸã„ ã³ã‚ˆã€œã‚“ ã«ã‚ƒ",
            "xaxis": "Elasticity (=âˆ‚E/âˆ‚xÂ·x/E) ã«ã‚ƒ",
            "expander_title": "ğŸ“˜ ã³ã‚ˆã€œã‚“ ã¨ã¯ï¼Ÿ ã«ã‚ƒ",
            "expander_content": (
                "1% ã†ã”ã‹ã™ã¨ **E_total** ãŒ ä½•% ã†ã”ãã‹ã‚’è¦‹ã‚‹ã«ã‚ƒã€‚\n"
                "å¤§ãã„å€¤ â†’ ã€ã›ã£ã‘ã„ ãŒã‚“ã°ã‚‹ ã¨ ã„ã„ã«ã‚ƒï¼ã€"
            ),
        },

        # 5) æ¨™æº–åŒ–æ„Ÿåº¦
        "standardized_sensitivity": {
            "title": "ã²ã‚‡ã†ã˜ã‚…ã‚“ã‹ ã‹ã‚“ã© ã«ã‚ƒ",
            "xaxis": "StdSens (=âˆ‚E/âˆ‚xÂ·Ïƒâ‚“/Ïƒ_E) ã«ã‚ƒ",
            "expander_title": "ğŸ“˜ ãƒªã‚¹ã‚¯ã«æ³¨æ„ã«ã‚ƒ",
            "expander_content": (
                "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã® ãµã‚‰ã¤ã (Ïƒ) ã‚’ã‹ã‘ã¦\n"
                "**E_total** ãŒ ã©ã‚Œã ã‘ ã‚†ã‚Œã‚‹ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã«ã‚ƒã€‚\n"
                "å¤§ãã„å€¤ â†’ ã€é‹ç”¨ã¡ã‚…ã† ãƒªã‚¹ã‚¯æ³¨æ„ï¼ã€"
            ),
        },

        # 6) ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­
        "monte_carlo": {
            "title": "ã‚‚ã‚“ã¦ ã‹ã‚‹ã‚ ã«ã‚ƒã€œ",
            "expander_title": "ğŸ“˜ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®ãŠã‚„ã¤ ã«ã‚ƒ",
            "expander_content": (
                "ãœã‚“ã¶ UI ã®ä»Šã®å€¤ã‚’ ã¾ã‚“ãªã‹ã« ãµã‚‰ãµã‚‰ã‚µãƒ³ãƒ—ãƒ«ã«ã‚ƒã€‚\n\n"
                "ãƒ»aâ‚,aâ‚‚ â†’ æ­£è¦(Â±3%) ã«ã‚ƒ\n"
                "ãƒ»aâ‚ƒ â†’ ä¸‰è§’(0.9ã€œ1.1) ã«ã‚ƒ\n"
                "ãƒ»bâ‚€ â†’ ä¸€æ§˜(Â±0.10) ã«ã‚ƒ\n"
                "ãƒ»CR,PP,â„“ â†’ ä¸‰è§’(0.8ã€œ1.2) ã«ã‚ƒ (ãœã‚ãªã‚‰å›ºå®šã«ã‚ƒ)\n"
                "ãƒ»Tâ‚â€“Tâ‚ƒ â†’ æ­£è¦(Â±10%) ã«ã‚ƒ\n\n"
                "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã«å¹³å‡ãƒ»ä¸­å¤®å€¤(å®Ÿç·š)ã¨ 5â€“95% (ç‚¹ç·š) ã‚’ãƒšã‚¿ãƒƒã¨ã«ã‚ƒã€‚"
            ),
            "variable": "ã¿ã‚‹å­ ã«ã‚ƒ",
            "mean": "ã¸ã„ãã‚“ ã«ã‚ƒ",
            "median": "ã¡ã‚…ã†ãŠã† ã«ã‚ƒ",
            "ci": "5â€“95% ã«ã‚ƒ",
            "caption": {
                "en": "Mean & Median = solid, CI = dotted ã«ã‚ƒ",
                "ja": "å¹³å‡/ä¸­å¤®å€¤=å®Ÿç·š, ä¿¡é ¼åŒºé–“=ç‚¹ç·š ã«ã‚ƒ"
            },
            "card_unit": "[E_total] ã«ã‚ƒ",
        },
    },
}

# ------ register all packs (order: EN is default) ------
TXT_ALL = {"EN": TXT_EN, "JA": TXT_JA, "CAT": TXT_CAT}   # â† ã“ã“ã§åˆã‚ã¦ã¾ã¨ã‚ã‚‹

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
#  SectionÂ 1  â€¢  Helper utilities
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def get_text_labels(lang: str) -> Dict:
    """Return languageâ€‘specific label dictionary."""
    LANG = "EN" if lang == "English" else "JA"
    return TXT_ALL[LANG]

def get_state(key, default):
    """Retrieve or initialise a value in `st.session_state`."""
    if key not in st.session_state:
        st.session_state[key] = default
    return st.session_state[key]

def exp(path: str):
    """
    Show markdown from nested TXT dict using dotâ€‘path key.
    Example: exp('charts.tornado.expander_title')
    """
    keys = path.split(".")
    title = TXT
    for k in keys:
        title = title[k]
    content_keys = keys[:-1] + [keys[-1].replace("_title", "_content")]
    content = TXT
    for k in content_keys:
        content = content[k]
    with st.expander(title, expanded=False):
        st.markdown(content)

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
#  SectionÂ 2  â€¢  Deterministic model
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def compute_metrics(
    a1v: float,
    a2v: float,
    a3v: float,
    bv: float,
    cross_ratio_v: float,
    prep_post_ratio_v: float,
    loss_unit_v: float,
    qualv: str,
    schedv: str,
    t1v: float,
    t2v: float,
    t3v: float,
) -> Tuple[float, float, float, float, float]:
    """Return S, C, C_loss, E, E_total for a single scenario."""
    # Multipliers
    qual_T, qual_B = (1, 1) if qualv == "Standard" else (2 / 3, 0.8)
    sched_T, sched_B = (1, 1) if schedv == "OnTime" else (2 / 3, 0.8)

    # Success probability
    a_tot = a1v * a2v * a3v
    b_eff = bv * qual_B * sched_B
    S_x = 1 - (1 - a_tot) * (1 - b_eff)

    # Costs
    T = (t1v + t2v + t3v) * qual_T * sched_T
    C_x = T * (1 + cross_ratio_v + prep_post_ratio_v)
    C_loss_x = C_x + loss_unit_v * C_x * (1 - S_x)

    # Efficiencies
    E_x = C_x / S_x
    E_total_x = C_loss_x / S_x
    return S_x, C_x, C_loss_x, E_x, E_total_x

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
#  SectionÂ 3  â€¢  Sensitivityâ€‘plot helper
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def make_sensitivity_bar(
    df: pd.DataFrame, value_col: str, tick_fmt: str = "{:.2f}", order=None
):
    """Horizontal bar (Plotly) for sensitivity tables."""
    df = df.copy()
    df[value_col] = df[value_col].abs()
    if order:
        df["Parameter"] = pd.Categorical(df["Parameter"], categories=order, ordered=True)
    fig = px.bar(
        df,
        x=value_col,
        y="Parameter",
        orientation="h",
        text=df[value_col].map(tick_fmt.format),
        color_discrete_sequence=["#000000"],
    )
    fig.update_traces(
        texttemplate="%{text}",
        insidetextfont_color="white",
        outsidetextfont_color="gray",
    )
    fig.update_layout(
        showlegend=False,
        yaxis=dict(categoryorder="array", categoryarray=order) if order else {},
        font=dict(size=14),
        bargap=0.1,
        margin=dict(t=30, b=40),
    )
    return fig

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
#  SectionÂ 4  â€¢  Config & localisation
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.set_page_config(page_title="Crossâ€‘Check Simulator", layout="wide")
if "lang" not in st.session_state:
    st.session_state.lang = "English"
lang_code = st.sidebar.radio(
    "Language / è¨€èª",                  # è¡¨ç¤ºãƒ©ãƒ™ãƒ«
    ["EN", "JA", "CAT"],               # å†…éƒ¨ã‚­ãƒ¼
    index=0,                           # ãƒ‡ãƒ•ã‚©ã¯ English
    format_func=lambda k: {"EN":"English",
                           "JA":"æ—¥æœ¬èª",
                           "CAT":"ğŸ˜¸ ã«ã‚ƒãƒ¼"}[k],
    horizontal=True,
)
TXT = TXT_ALL[lang_code]               # ã“ã“ã ã‘ã§å…¨ UI åˆ‡æ›¿

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
#  SectionÂ 5  â€¢  Sidebar inputs  (rooted in UI)
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def get_sidebar_params() -> Dict[str, float]:
    st.sidebar.title(TXT["panel"]["input"])

    # ---- åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå®Ÿç¸¾ã‚ã‚Šï¼‰ --------------------------
    st.sidebar.subheader("âœ… ReliableÂ (Gerrit / COCOMO)")

    a1 = st.sidebar.slider("a1Â (stepâ€¯1)", 0.5, 1.0,
                           get_state("a1", 0.95), 0.01)
    a2 = st.sidebar.slider("a2Â (stepâ€¯2)", 0.5, 1.0,
                           get_state("a2", 0.95), 0.01)
    a3 = st.sidebar.slider("a3Â (stepâ€¯3)", 0.5, 1.0,
                           get_state("a3", 0.80), 0.01)

    # ---- Quality & Schedule (é›¢æ•£) ----------------------------
    col_q, col_s = st.sidebar.columns(2)
    with col_q:
        qual = st.selectbox("Quality",
                            ["Standard", "Low"],
                            index=0 if get_state("qual", "Standard") == "Standard" else 1,
                            key="qual")
    with col_s:
        sched = st.selectbox("Schedule",
                             ["OnTime", "Late"],
                             index=0 if get_state("sched", "OnTime") == "OnTime" else 1,
                             key="sched")

    b0 = st.sidebar.slider("bâ‚€Â (checker skill)", 0.0, 1.0,
                           get_state("b0", 0.80), 0.01)
    cross_ratio = st.sidebar.slider("CRÂ (crossâ€‘ratio)",
                                    0.0, 0.5,
                                    get_state("cross_ratio", 0.30), 0.01)

    # ---- ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ -----------------------------
    st.sidebar.subheader("ğŸ”¶ Highâ€‘uncertaintyÂ (Adjustâ€¯&â€¯Watch)")

    # Bold heading for PP
    st.sidebar.markdown("**PP (Prep/Post ratio)**")
    prep_post_ratio = st.sidebar.slider("", 0.0, 0.5,
                                        get_state("prep_post_ratio", 0.40),
                                        0.01, label_visibility="collapsed")

    st.sidebar.markdown("**â„“Â (Loss unit)**")
    loss_unit = st.sidebar.slider("", 0.0, 50.0,
                                  get_state("loss_unit", 0.0),
                                  0.5, label_visibility="collapsed")

    st.sidebar.markdown("**Tâ‚â€“Tâ‚ƒÂ (Task hours)**")
    col_t1, col_t2, col_t3 = st.sidebar.columns(3)
    with col_t1:
        T1 = st.number_input("Tâ‚Â [h]", 0, 200,
                             get_state("T1", 10), key="T1")
    with col_t2:
        T2 = st.number_input("Tâ‚‚Â [h]", 0, 200,
                             get_state("T2", 10), key="T2")
    with col_t3:
        T3 = st.number_input("Tâ‚ƒÂ [h]", 0, 200,
                             get_state("T3", 30), key="T3")

    # ---- Monteâ€¯Carlo settings ---------------------------------
    st.sidebar.markdown("---")
    st.sidebar.title("Monteâ€‘Carlo")
    col_n, col_var = st.sidebar.columns(2)
    with col_n:
        sample_n = st.number_input("Samples",
                                   1_000, 1_000_000,
                                   get_state("sample_n", 100_000),
                                   step=10_000)
    with col_var:
        mc_var = st.selectbox("MC variable",
                              ["E_total", "Successâ€¯S"], 0,
                              key="mc_var")

    return dict(
        a1=a1, a2=a2, a3=a3, b0=b0,
        cross_ratio=cross_ratio, prep_post_ratio=prep_post_ratio,
        loss_unit=loss_unit,
        T1=T1, T2=T2, T3=T3,
        qual=qual, sched=sched,
        sample_n=sample_n, mc_var=mc_var,
    )

params = get_sidebar_params()

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
#  SectionÂ 6  â€¢  Monteâ€‘Carlo simulation  (all Â±Î± % around UI)
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@st.cache_data(show_spinner=False, ttl=900)
def run_mc(p: Dict[str, float], N: int) -> Tuple[np.ndarray, ...]:
    """Vectorised Monteâ€‘Carlo; returns Evals, Svals, Cvals, L_samples."""
    rng = Generator(PCG64DXSM(seed=0))

    # Success rates
    a1s = rng.normal(p["a1"], max(0.01, p["a1"] * 0.03), N).clip(0, 1)
    a2s = rng.normal(p["a2"], max(0.01, p["a2"] * 0.03), N).clip(0, 1)
    a3s = rng.triangular(p["a3"] * 0.9, p["a3"], p["a3"] * 1.1, N).clip(0, 1)
    b0s = rng.uniform(max(0, p["b0"] - 0.10), min(1, p["b0"] + 0.10), N)

    # Task times (Â±10â€¯%)
    t1s = rng.normal(p["T1"], p["T1"] * 0.10, N).clip(min=1)
    t2s = rng.normal(p["T2"], p["T2"] * 0.10, N).clip(min=1)
    t3s = rng.normal(p["T3"], p["T3"] * 0.10, N).clip(min=1)

    # Cost ratios & loss
    CRs = (
        rng.triangular(p["cross_ratio"] * 0.8, p["cross_ratio"],
                    p["cross_ratio"] * 1.2, N)
        if p["cross_ratio"] > 0
        else np.zeros(N)
    )
    PPs = (
        rng.triangular(p["prep_post_ratio"] * 0.8, p["prep_post_ratio"],
                    p["prep_post_ratio"] * 1.2, N)
        if p["prep_post_ratio"] > 0
        else np.zeros(N)
    )
    Ls = (
        rng.triangular(p["loss_unit"] * 0.8, p["loss_unit"],
                    p["loss_unit"] * 1.2, N)
        if p["loss_unit"] > 0
        else np.zeros(N)
    )

    # Multipliers
    qual_T, qual_B = (1, 1) if p["qual"] == "Standard" else (2 / 3, 0.8)
    sched_T, sched_B = (1, 1) if p["sched"] == "OnTime" else (2 / 3, 0.8)

    a_tot = a1s * a2s * a3s
    b_eff = b0s * qual_B * sched_B
    Svals = 1 - (1 - a_tot) * (1 - b_eff)

    Tvals = (t1s + t2s + t3s) * qual_T * sched_T
    Cvals = Tvals * (1 + CRs + PPs)
    Evals = (Cvals + Ls * Cvals * (1 - Svals)) / Svals
    return Evals, Svals, Cvals, Ls

Evals, Svals, Cvals, L_samples = run_mc(params, int(params["sample_n"]))
ÏƒE, ÏƒC, ÏƒS, ÏƒL = Evals.std(), Cvals.std(), Svals.std(), (Cvals * L_samples).std()

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
#  SectionÂ 7  â€¢  Sobol global sensitivity (UIâ€‘relative bounds)
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@st.cache_data(show_spinner=False, ttl=900)
def run_sobol(p: Dict[str, float], N: int = 10_000) -> pd.DataFrame:
    """
    Sobol analysis with bounds defined as (UI value Â±â€¯Î±â€¯%)
    Î± = 3â€¯% for aâ‚,aâ‚‚, 10â€¯% aâ‚ƒ, 10â€¯% T, 20â€¯% CR/PP/â„“, 0.10 for bâ‚€.
    """
    # Bounds helper
    def clip(lo, hi, low=0.0, high=1e9, eps=1e-6):
        lo_c = max(low, lo)
        hi_c = min(high, hi)
        if hi_c <= lo_c:          # å¹…ã‚¼ãƒ­ã‚’å›é¿
            hi_c = lo_c + eps
        return [lo_c, hi_c]


    problem = {
        "num_vars": 10,  # a1,a2,a3,b0,CR,PP,L,T1,T2,T3
        "names": ["a1","a2","a3","b0","CR","PP","L",
                  "T1","T2","T3"],
        "bounds": [
            clip(p["a1"]*0.97, p["a1"]*1.03, 0, 1),
            clip(p["a2"]*0.97, p["a2"]*1.03, 0, 1),
            clip(p["a3"]*0.90, p["a3"]*1.10, 0, 1),
            clip(p["b0"]-0.10, p["b0"]+0.10, 0, 1),
            clip(p["cross_ratio"]*0.8, p["cross_ratio"]*1.2, 0, 0.5),
            clip(p["prep_post_ratio"]*0.8, p["prep_post_ratio"]*1.2, 0, 0.5),
            clip(p["loss_unit"]*0.8, p["loss_unit"]*1.2, 0, 50),
            clip(p["T1"]*0.9, p["T1"]*1.1, 1, 1e3),
            clip(p["T2"]*0.9, p["T2"]*1.1, 1, 1e3),
            clip(p["T3"]*0.9, p["T3"]*1.1, 1, 1e3),
        ]
    }
    # -- If you need qual_F / sched_F, uncomment lines below ----
    # problem["names"] += ["qual_F","sched_F"]
    # problem["bounds"] += [[0.8,1.0],[0.8,1.0]]
    # problem["num_vars"] = len(problem["names"])
    # -----------------------------------------------------------

    # Saltelli requires N = 2^k
    np.random.seed(0)
    N_pow2 = 2 ** math.ceil(math.log2(N))
    if N_pow2 != N:
        st.info(f"Sobol samples adjusted to {N_pow2} (nearest powerâ€‘ofâ€‘2).")
    X = sobol_sample(problem, N_pow2, calc_second_order=False)

    # Unpack X
    a_tot = X[:,0] * X[:,1] * X[:,2]
    b_eff = X[:,3] * (1 if params["qual"]=="Standard" else 0.8) \
                     * (1 if params["sched"]=="OnTime" else 0.8)
    Sarr = 1 - (1 - a_tot) * (1 - b_eff)

    Tarr = (X[:,7] + X[:,8] + X[:,9]) * \
           (1 if params["qual"]=="Standard" else 2/3) * \
           (1 if params["sched"]=="OnTime" else 2/3)
    Cbase = Tarr * (1 + X[:,4] + X[:,5])
    E_tot = (Cbase + X[:,6] * Cbase * (1 - Sarr)) / Sarr

    Si = sobol.analyze(problem, E_tot,
                       calc_second_order=False, print_to_console=False)
    df = pd.DataFrame({"Parameter": problem["names"],
                       "S1": Si["S1"], "ST": Si["ST"]})
    return df.sort_values("S1", ascending=False)

df_sobol = run_sobol(params)

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
#  SectionÂ 8  â€¢  Deterministic baseline
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
qual_T, qual_B = (1,1) if params["qual"]=="Standard" else (2/3,0.8)
sched_T, sched_B = (1,1) if params["sched"]=="OnTime" else (2/3,0.8)

a_total = params["a1"]*params["a2"]*params["a3"]
b_eff   = params["b0"]*qual_B*sched_B
S = 1 - (1 - a_total)*(1 - b_eff)
T = (params["T1"]+params["T2"]+params["T3"])*qual_T*sched_T
C = T * (1 + params["cross_ratio"] + params["prep_post_ratio"])
C_loss = C + params["loss_unit"]*C*(1 - S)
E = C / S
E_total = C_loss / S

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
#  SectionÂ 9  â€¢  Local elasticities (symbolic)
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def symbolic_derivatives(C_:float,S_:float,L_:float)->Dict[str,float]:
    C_sym,S_sym,L_sym=sp.symbols("C S L")
    E_expr=(C_sym+C_sym*L_sym*(1-S_sym))/S_sym
    return {
        "dE_dC":float(sp.diff(E_expr,C_sym).subs({C_sym:C_,S_sym:S_,L_sym:L_})),
        "dE_dS":float(sp.diff(E_expr,S_sym).subs({C_sym:C_,S_sym:S_,L_sym:L_})),
        "dE_dL":float(sp.diff(E_expr,L_sym).subs({C_sym:C_,S_sym:S_,L_sym:L_})),
    }
derivs=symbolic_derivatives(C,S,params["loss_unit"])
rel_C,rel_S,rel_L = (derivs["dE_dC"]*C/E_total,
                     derivs["dE_dS"]*S/E_total,
                     derivs["dE_dL"]*params["loss_unit"]/E_total)
std_C,std_S,std_L = (derivs["dE_dC"]*ÏƒC/ÏƒE,
                     derivs["dE_dS"]*ÏƒS/ÏƒE,
                     derivs["dE_dL"]*ÏƒL/ÏƒE)

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
#  SectionÂ 10 â€¢  Layout & plots
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
left,right = st.columns([1,2])
with left:
    st.subheader(TXT["panel"]["output"])
    st.metric(TXT["metrics"]["a_total"], f"{a_total:.4f}")
    st.metric(TXT["metrics"]["succ"],   f"{S:.2%}")
    st.metric(TXT["metrics"]["C"],      f"{C:.1f}")
    st.metric(TXT["metrics"]["Closs"],  f"{C_loss:.1f}")
    st.metric(TXT["metrics"]["E_base"], f"{E:.1f}")
    st.metric(TXT["metrics"]["E_total"],f"{E_total:.1f}")

with right:
    # --- Quality Ã— Schedule bar -------------------------------
    st.subheader(TXT["charts"]["quality_schedule"]["title"])
    exp("charts.quality_schedule.expander_title")

    scenarios=[("Std/On","Standard","OnTime"),
               ("Std/Late","Standard","Late"),
               ("Low/On","Low","OnTime"),
               ("Low/Late","Low","Late")]
    bars=[]
    for lbl,qg,scd in scenarios:
        S_qs,_,_,_,E_qs=compute_metrics(
            a1v=params["a1"],a2v=params["a2"],a3v=params["a3"],
            bv=params["b0"],cross_ratio_v=params["cross_ratio"],
            prep_post_ratio_v=params["prep_post_ratio"],
            loss_unit_v=params["loss_unit"],
            qualv=qg,schedv=scd,
            t1v=params["T1"],t2v=params["T2"],t3v=params["T3"])
        bars.append(dict(Scenario=lbl,E_total=E_qs,S=f"{S_qs:.1%}"))
    fig_qs=px.bar(pd.DataFrame(bars),x="Scenario",y="E_total",text="S",
                  color_discrete_sequence=["#000000"],
                  labels={"E_total":TXT["metrics"]["E_total"],"Scenario":""})
    fig_qs.update_traces(textposition="auto",
                         insidetextfont_color="white",
                         outsidetextfont_color="gray")
    fig_qs.update_layout(font=dict(size=14),bargap=0.1,
                         margin=dict(t=30,b=40))
    st.plotly_chart(fig_qs,use_container_width=True)

    # --- Tornado ----------------------------------------------
    st.subheader(TXT["charts"]["tornado"]["title"])
    exp("charts.tornado.expander_title")
    sens_targets={"a1":params["a1"],"a2":params["a2"],"a3":params["a3"],
                  "b0":params["b0"],"CR":params["cross_ratio"],
                  "PP":params["prep_post_ratio"],"L":params["loss_unit"]}
    name_map={"a1":"a1v","a2":"a2v","a3":"a3v",
              "b0":"bv","CR":"cross_ratio_v",
              "PP":"prep_post_ratio_v","L":"loss_unit_v"}
    tornado=[]
    for k,base in sens_targets.items():
        lo=max(base*0.8,0)
        hi=min(base*1.2,1) if k in ("a1","a2","a3","b0") else base*1.2
        def e_tot(**ov):
            kw=dict(a1v=params["a1"],a2v=params["a2"],a3v=params["a3"],
                    bv=params["b0"],cross_ratio_v=params["cross_ratio"],
                    prep_post_ratio_v=params["prep_post_ratio"],
                    loss_unit_v=params["loss_unit"],
                    qualv=params["qual"],schedv=params["sched"],
                    t1v=params["T1"],t2v=params["T2"],t3v=params["T3"])
            kw.update(ov); return compute_metrics(**kw)[4]
        delta=max(abs(e_tot(**{name_map[k]:lo})-E_total),
                  abs(e_tot(**{name_map[k]:hi})-E_total))/E_total
        tornado.append((k,delta))
    df_tornado=pd.DataFrame(tornado,columns=["Parameter","RelChange"])\
                 .sort_values("RelChange",ascending=False)
    fig_tornado=make_sensitivity_bar(
        df_tornado.rename(columns={"RelChange":"Tornado"}),
        value_col="Tornado",tick_fmt="{:.2%}",
        order=df_tornado["Parameter"].tolist())
    st.plotly_chart(fig_tornado,use_container_width=True)

    # --- Sobol -------------------------------------------------
    st.subheader(TXT["charts"]["sobol"]["title"])
    exp("charts.sobol.expander_title")
    fig_sobol=make_sensitivity_bar(
        df_sobol[["Parameter","S1"]].rename(columns={"S1":"Sobol"}),
        value_col="Sobol",tick_fmt="{:.2f}",
        order=df_sobol["Parameter"].tolist())
    st.plotly_chart(fig_sobol,use_container_width=True)

    # --- Relative / Standardised ------------------------------
    sens_df=pd.DataFrame(dict(
        Parameter=[TXT["metrics"]["loss_unit"],
                   TXT["metrics"]["C"],
                   TXT["metrics"]["succ"]],
        Relative=[abs(rel_L),abs(rel_C),abs(rel_S)],
        Standardised=[abs(std_L),abs(std_C),abs(std_S)]))
    order=sens_df["Parameter"].tolist()
    fig_rel=make_sensitivity_bar(
        sens_df[["Parameter","Relative"]].rename(columns={"Relative":"rel"}),
        value_col="rel",order=order,tick_fmt="{:.2f}")
    fig_std=make_sensitivity_bar(
        sens_df[["Parameter","Standardised"]].rename(columns={"Standardised":"std"}),
        value_col="std",order=order,tick_fmt="{:.3f}")

# -- Display sideâ€‘byâ€‘side
col_rel,col_std=st.columns(2)
with col_rel:
    col_rel.subheader(TXT["charts"]["relative_sensitivity"]["title"])
    exp("charts.relative_sensitivity.expander_title")
    col_rel.plotly_chart(fig_rel,use_container_width=True)
with col_std:
    col_std.subheader(TXT["charts"]["standardized_sensitivity"]["title"])
    exp("charts.standardized_sensitivity.expander_title")
    col_std.plotly_chart(fig_std,use_container_width=True)

# â•â•â•â•â• MonteÂ Carlo histogram â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.subheader(TXT["charts"]["monte_carlo"]["title"])
exp("charts.monte_carlo.expander_title")
data = Evals if params["mc_var"]=="E_total" else Svals
ci_low,ci_high=np.percentile(data,[5,95])
mean,median=data.mean(),np.median(data)
dec=".2f" if params["mc_var"]=="E_total" else ".4f"
c1,c2,c3=st.columns(3)
c1.metric(TXT["charts"]["monte_carlo"]["mean"]+TXT["charts"]["monte_carlo"]["card_unit"],
          f"{mean:{dec}}")
c2.metric(TXT["charts"]["monte_carlo"]["median"]+TXT["charts"]["monte_carlo"]["card_unit"],
          f"{median:{dec}}")
c3.metric(TXT["charts"]["monte_carlo"]["ci"]+TXT["charts"]["monte_carlo"]["card_unit"],
          f"{ci_low:{dec}}Â â€“Â {ci_high:{dec}}")

# âœ… æ–°ã—ã„ï¼ˆlang â†’ lang_codeï¼‰
label_E   = "E_total" if lang_code=="EN" else ("E_total: ç·åˆåŠ¹ç‡" if lang_code=="JA" else "E_total ã«ã‚ƒ")
label_cnt = "Count"   if lang_code=="EN" else ("é »åº¦"                 if lang_code=="JA" else "ã‹ãš ã«ã‚ƒ")
fig_hist=px.histogram(data,nbins=100,
                      labels={"value":label_E},
                      color_discrete_sequence=["#000000"])
fig_hist.update_traces(marker_line_width=0.5)
for x,style in [(mean,"solid"),(median,"solid"),
                (ci_low,"dot"),(ci_high,"dot")]:
    fig_hist.add_vline(x=x,line_dash=style,line_color="#000000")
fig_hist.update_layout(yaxis_title=label_cnt,bargap=0.01,
                       margin=dict(t=70),showlegend=False)
st.plotly_chart(fig_hist,use_container_width=True)
legend    = "Mean / Median: solid  5â€“95 % CI: dotted" if lang_code=="EN" \
          else ("å¹³å‡/ä¸­å¤®å€¤ï¼šå®Ÿç·š  ä¿¡é ¼åŒºé–“5â€“95 %ï¼šç‚¹ç·š"            if lang_code=="JA"
          else  "å¹³å‡/ä¸­å¤®å€¤=ç·šã«ã‚ƒ  CI=ç‚¹ç·šã«ã‚ƒ")
st.caption(legend)
